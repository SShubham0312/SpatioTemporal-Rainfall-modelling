{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b8937c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e7f407",
   "metadata": {},
   "source": [
    "# XGB (class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fad2ea0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ---------------- Load the final dataframe ----------------\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# write code below to load a dataframe in a directory not direclty in this directory\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# ---------------- Load the final dataframe ----------------\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Ignore rows where Station == 'COLABA_-_IMD_OBSY_1854.0_7249.0'\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m df = \u001b[43mpd\u001b[49m.read_csv(\u001b[33m'\u001b[39m\u001b[33mstation_outputs/DHARMABAD_1853.0_7750.0.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m#df = df[df['Station'] != 'COLABA_-_IMD_OBSY_1854.0_7249.0']\u001b[39;00m\n\u001b[32m      7\u001b[39m df = df.drop(columns=[\u001b[33m'\u001b[39m\u001b[33mStation\u001b[39m\u001b[33m'\u001b[39m], errors=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# ---------------- Load the final dataframe ----------------\n",
    "# write code below to load a dataframe in a directory not direclty in this directory\n",
    "# ---------------- Load the final dataframe ----------------\n",
    "# Ignore rows where Station == 'COLABA_-_IMD_OBSY_1854.0_7249.0'\n",
    "df = pd.read_csv('station_outputs/DHARMABAD_1853.0_7750.0.csv')\n",
    "#df = df[df['Station'] != 'COLABA_-_IMD_OBSY_1854.0_7249.0']\n",
    "df = df.drop(columns=['Station'], errors='ignore')\n",
    "df = df.drop(columns=['Date'], errors='ignore')\n",
    "\n",
    "rainfall_threshold = df['Rainfall'].quantile(0.85)\n",
    "df['Rainfall'] = (df['Rainfall'] >= rainfall_threshold).astype(int)\n",
    "\n",
    "X = df.iloc[:, :-1]  \n",
    "y = df.iloc[:, -1]   \n",
    "\n",
    "# ---------------- Train-test split ----------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "scale_pos_weight = y_train.value_counts()[0] / y_train.value_counts()[1]\n",
    "# ---------------- Train XGBoost model ----------------\n",
    "model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    scale_pos_weight=scale_pos_weight\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ---------------- Evaluation ----------------\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cae34ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hit Rate: 0.18\n",
      "False Alarm Rate: 0.06\n",
      "Threat Score: 0.14\n"
     ]
    }
   ],
   "source": [
    "# print hit rate , false alarm rate and threat score from these metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    \n",
    "    hit_rate = tp / (tp + fn) \n",
    "    false_alarm_rate = fp / (fp + tn) \n",
    "    threat_score = tp / (tp + fp + fn) \n",
    "    \n",
    "    return hit_rate, false_alarm_rate, threat_score\n",
    "hit_rate, false_alarm_rate, threat_score = calculate_metrics(y_test, y_pred)\n",
    "print(f\"\\nHit Rate: {hit_rate:.2f}\")\n",
    "print(f\"False Alarm Rate: {false_alarm_rate:.2f}\")\n",
    "print(f\"Threat Score: {threat_score:.2f}\")\n",
    "# Save the model to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58091d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8659058487874465\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92       575\n",
      "           1       0.60      0.78      0.68       126\n",
      "\n",
      "    accuracy                           0.87       701\n",
      "   macro avg       0.77      0.83      0.80       701\n",
      "weighted avg       0.88      0.87      0.87       701\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[509  66]\n",
      " [ 28  98]]\n",
      "   R_H_L100_00_f018  R_H_L100_00_f021  R_H_L100_00_f024  R_H_L100_00_f027  \\\n",
      "0         96.707827         97.804086         96.366209         96.530411   \n",
      "1         81.075206         86.335429         89.188677         87.674318   \n",
      "2         85.684209         92.796396         97.554642         92.261322   \n",
      "3         96.614821         87.513717         98.047336         96.483134   \n",
      "4         98.052580         96.079917         95.405591         94.543160   \n",
      "\n",
      "   R_H_L100_00_f030  R_H_L100_00_f033  R_H_L100_00_f036  R_H_L100_00_f039  \\\n",
      "0         97.645203         98.641175         99.160912         95.474610   \n",
      "1         89.159703         92.926363         91.714839         94.827384   \n",
      "2         96.072126         94.759819         92.416743         94.352499   \n",
      "3         95.986175         93.489331         91.093738         97.491556   \n",
      "4         97.108401         90.767002         94.189852         96.823458   \n",
      "\n",
      "   R_H_L100_00_f042  TMP_L100_00_f018  ...  PRATE_L1_18_f027  \\\n",
      "0         82.256030        236.653324  ...          0.000733   \n",
      "1         89.772765        237.012455  ...          0.000000   \n",
      "2         96.589548        237.138476  ...          0.000400   \n",
      "3         97.379111        237.629958  ...          0.000000   \n",
      "4         97.288050        238.456961  ...          0.000188   \n",
      "\n",
      "   PRATE_L1_18_f030  PRATE_L1_18_f033  PRATE_L1_18_f036  PRATE_L1_18_f039  \\\n",
      "0          0.000644          0.000789            0.0008            0.0002   \n",
      "1          0.000245          0.000338            0.0005            0.0003   \n",
      "2          0.000398          0.000288            0.0003            0.0002   \n",
      "3          0.000000          0.000000            0.0000            0.0000   \n",
      "4          0.000179          0.000241            0.0003            0.0001   \n",
      "\n",
      "   PRATE_L1_18_f042  PRATE_L1_18_f045  PRATE_L1_18_f048  Rainfall  \\\n",
      "0          0.000353          0.000072          0.000000         1   \n",
      "1          0.000559          0.000517          0.000326         1   \n",
      "2          0.000126          0.000156          0.000162         1   \n",
      "3          0.000199          0.000062          0.000026         0   \n",
      "4          0.000282          0.000244          0.000212         0   \n",
      "\n",
      "   Predicted_Rainfall  \n",
      "0                   1  \n",
      "1                   1  \n",
      "2                   1  \n",
      "3                   0  \n",
      "4                   0  \n",
      "\n",
      "[5 rows x 182 columns]\n",
      "\n",
      "Hit Rate: 0.78\n",
      "False Alarm Rate: 0.11\n",
      "Threat Score: 0.51\n"
     ]
    }
   ],
   "source": [
    "# --- Predict and evaluate on a new file with ground truth ---\n",
    "\n",
    "# Load the new data\n",
    "new_df = pd.read_csv('overall_binarized_outputs/subset_18.9_72.8167.csv')\n",
    "\n",
    "# Drop columns not needed for prediction\n",
    "new_df = new_df.drop(columns=['station_lat', 'station_lon', 'month', 'dayofyear'], errors='ignore')\n",
    "\n",
    "# Extract ground truth\n",
    "y_true = new_df['Rainfall']\n",
    "\n",
    "# Drop 'Rainfall' from features\n",
    "X_new = new_df.drop(columns=['Rainfall'], errors='ignore')\n",
    "\n",
    "# Predict using the trained model\n",
    "y_pred = model.predict(X_new)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "\n",
    "# Optionally, add predictions to the dataframe and save\n",
    "new_df['Predicted_Rainfall'] = y_pred\n",
    "new_df.to_csv('predicted_results_with_truth.csv', index=False)\n",
    "print(new_df.head())\n",
    "\n",
    "# print hit rate , false alarm rate and threat score from these metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    \n",
    "    hit_rate = tp / (tp + fn) \n",
    "    false_alarm_rate = fp / (fp + tn) \n",
    "    threat_score = tp / (tp + fp + fn) \n",
    "    \n",
    "    return hit_rate, false_alarm_rate, threat_score\n",
    "hit_rate, false_alarm_rate, threat_score = calculate_metrics(y_true, y_pred)\n",
    "print(f\"\\nHit Rate: {hit_rate:.2f}\")\n",
    "print(f\"False Alarm Rate: {false_alarm_rate:.2f}\")\n",
    "print(f\"Threat Score: {threat_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2276657e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2260430",
   "metadata": {},
   "source": [
    "# XGB (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5437a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manoj/Desktop/MH/.venv/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [11:28:13] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8723252496433667\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92      3573\n",
      "           1       0.56      0.69      0.62       633\n",
      "\n",
      "    accuracy                           0.87      4206\n",
      "   macro avg       0.75      0.80      0.77      4206\n",
      "weighted avg       0.89      0.87      0.88      4206\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3231  342]\n",
      " [ 195  438]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------------- Load the final dataframe ----------------\n",
    "df = pd.read_csv('combined_interpolated_data.csv')\n",
    "df = df.drop(columns=['Station'], errors='ignore')\n",
    "df = df.drop(columns=['Date'], errors='ignore')\n",
    "\n",
    "rainfall_threshold = df['Rainfall'].quantile(0.85)\n",
    "df['Rainfall'] = (df['Rainfall'] >= rainfall_threshold).astype(int)\n",
    "\n",
    "X = df.iloc[:, :-1]  \n",
    "y = df.iloc[:, -1]   \n",
    "scale_pos_weight = y_train.value_counts()[0] / y_train.value_counts()[1]\n",
    "\n",
    "# ---------------- Train-test split ----------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ---------------- Apply SMOTE only on training data ----------------\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# ---------------- Train XGBoost model ----------------\n",
    "model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# ---------------- Evaluation ----------------\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "144f639d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hit Rate: 0.69\n",
      "False Alarm Rate: 0.10\n",
      "Threat Score: 0.45\n"
     ]
    }
   ],
   "source": [
    "# print hit rate , false alarm rate and threat score from these metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    \n",
    "    hit_rate = tp / (tp + fn) \n",
    "    false_alarm_rate = fp / (fp + tn) \n",
    "    threat_score = tp / (tp + fp + fn) \n",
    "    \n",
    "    return hit_rate, false_alarm_rate, threat_score\n",
    "hit_rate, false_alarm_rate, threat_score = calculate_metrics(y_test, y_pred)\n",
    "print(f\"\\nHit Rate: {hit_rate:.2f}\")\n",
    "print(f\"False Alarm Rate: {false_alarm_rate:.2f}\")\n",
    "print(f\"Threat Score: {threat_score:.2f}\")\n",
    "# Save the model to a file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37b051d",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11566334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.889205896338564\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      3573\n",
      "           1       0.65      0.57      0.61       633\n",
      "\n",
      "    accuracy                           0.89      4206\n",
      "   macro avg       0.79      0.76      0.77      4206\n",
      "weighted avg       0.88      0.89      0.89      4206\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3379  194]\n",
      " [ 272  361]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------------- Load the final dataframe ----------------\n",
    "df = pd.read_csv('combined_interpolated_data.csv')\n",
    "df = df.drop(columns=['Station'], errors='ignore')\n",
    "df = df.drop(columns=['Date'], errors='ignore')\n",
    "\n",
    "# ---------------- Label rainfall as binary ----------------\n",
    "rainfall_threshold = df['Rainfall'].quantile(0.85)\n",
    "df['Rainfall'] = (df['Rainfall'] >= rainfall_threshold).astype(int)\n",
    "\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "# ---------------- Train-test split ----------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ---------------- Train Random Forest model ----------------\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    class_weight='balanced',  # handles imbalance by adjusting weights\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ---------------- Evaluation ----------------\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f131563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hit Rate: 0.57\n",
      "False Alarm Rate: 0.05\n",
      "Threat Score: 0.44\n"
     ]
    }
   ],
   "source": [
    "# print hit rate , false alarm rate and threat score from these metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    \n",
    "    hit_rate = tp / (tp + fn) \n",
    "    false_alarm_rate = fp / (fp + tn) \n",
    "    threat_score = tp / (tp + fp + fn) \n",
    "    \n",
    "    return hit_rate, false_alarm_rate, threat_score\n",
    "hit_rate, false_alarm_rate, threat_score = calculate_metrics(y_test, y_pred)\n",
    "print(f\"\\nHit Rate: {hit_rate:.2f}\")\n",
    "print(f\"False Alarm Rate: {false_alarm_rate:.2f}\")\n",
    "print(f\"Threat Score: {threat_score:.2f}\")\n",
    "# Save the model to a file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
