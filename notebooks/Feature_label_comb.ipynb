{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49a37b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing station files: 100%|██████████| 292/292 [00:18<00:00, 15.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged dataset saved to combined_dataset.csv with shape (139037, 188)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Paths\n",
    "station_data_dir = 'per_station_data'\n",
    "gfs_data_dir = 'output_features'\n",
    "output_file = 'combined_dataset.csv'\n",
    "\n",
    "# Helper: Extract decimal lat/lon from station filename\n",
    "def extract_station_coords(filename):\n",
    "    try:\n",
    "        parts = filename.replace('.csv', '').split('_')\n",
    "        lat4 = float(parts[-2])     # e.g., 1435.0\n",
    "        lon4 = float(parts[-1])     # e.g., 7656.0\n",
    "        if lat4 == 9999.0 or lon4 == 9999.0:\n",
    "            return None\n",
    "        return round(lat4 / 100.0, 2), round(lon4 / 100.0, 2)  # → (14.35, 76.56)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Helper: Snap to nearest 0.25° GFS grid point\n",
    "def snap_to_grid(lat, lon):\n",
    "    return round(lat * 4) / 4, round(lon * 4) / 4  # e.g., 14.35 → 14.25\n",
    "\n",
    "# Gather all station files\n",
    "all_merged_rows = []\n",
    "\n",
    "station_files = [f for f in os.listdir(station_data_dir) if f.endswith('.csv')]\n",
    "\n",
    "for station_file in tqdm(station_files, desc=\"Processing station files\"):\n",
    "    coords = extract_station_coords(station_file)\n",
    "    if coords is None:\n",
    "        continue\n",
    "\n",
    "    station_lat, station_lon = coords\n",
    "    grid_lat, grid_lon = snap_to_grid(station_lat, station_lon)\n",
    "\n",
    "    gfs_filename = f\"lat_{grid_lat}_lon_{grid_lon}.csv\"\n",
    "    gfs_path = os.path.join(gfs_data_dir, gfs_filename)\n",
    "    station_path = os.path.join(station_data_dir, station_file)\n",
    "\n",
    "    if not os.path.exists(gfs_path):\n",
    "        print(f\"GFS file not found: {gfs_filename}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        gfs_df = pd.read_csv(gfs_path)\n",
    "        gfs_df['date'] = pd.to_datetime(gfs_df['date'])\n",
    "\n",
    "        station_df = pd.read_csv(station_path)\n",
    "        station_df['date'] = pd.to_datetime(station_df['Date'])  # Rename for merge\n",
    "\n",
    "        merged_df = pd.merge(gfs_df, station_df, on='date', how='inner')\n",
    "\n",
    "        merged_df['station_lat'] = station_lat\n",
    "        merged_df['station_lon'] = station_lon\n",
    "        merged_df['grid_lat'] = grid_lat\n",
    "        merged_df['grid_lon'] = grid_lon\n",
    "        merged_df['station_file'] = station_file\n",
    "\n",
    "        all_merged_rows.append(merged_df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error merging {station_file}: {e}\")\n",
    "\n",
    "# Save final combined dataset\n",
    "if all_merged_rows:\n",
    "    final_df = pd.concat(all_merged_rows, ignore_index=True)\n",
    "    final_df.to_csv(output_file, index=False)\n",
    "    print(f\"✅ Merged dataset saved to {output_file} with shape {final_df.shape}\")\n",
    "else:\n",
    "    print(\"❌ No data merged. Check for matching GFS files or date mismatches.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d2fbab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85th percentile threshold: 26.00 mm\n",
      "label\n",
      "low     117904\n",
      "high     21133\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('combined_dataset.csv')\n",
    "\n",
    "# Replace this with your actual rainfall column name:\n",
    "rain_col = 'Rainfall'  # e.g., 'Rainfall' or 'target' or whatever you find\n",
    "\n",
    "# Step 1: Calculate 85th percentile\n",
    "threshold = df[rain_col].quantile(0.85)\n",
    "\n",
    "# Step 2: Create labels\n",
    "df['label'] = df[rain_col].apply(lambda x: 'high' if x >= threshold else 'low')\n",
    "\n",
    "# Step 3 (Optional): Numeric encoding\n",
    "df['label_num'] = df['label'].map({'low': 0, 'high': 1})\n",
    "\n",
    "# Save the result\n",
    "df.to_csv('classified_combined_data.csv', index=False)\n",
    "\n",
    "print(f\"85th percentile threshold: {threshold:.2f} mm\")\n",
    "print(df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61af59ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load the combined CSV\n",
    "df = pd.read_csv(\"classified_combined_data.csv\")\n",
    "\n",
    "# Convert 'date' column to datetime\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Extract temporal features\n",
    "df['month'] = df['date'].dt.month\n",
    "df['dayofyear'] = df['date'].dt.dayofyear\n",
    "\n",
    "# Drop 'date' column if not needed\n",
    "df.drop(columns=['date'], inplace=True)\n",
    "\n",
    "# Define feature columns (0-159 weather + 183-186 lat/lon + 190-191 temporal)\n",
    "feature_columns = list(df.columns[0:180]) + list(df.columns[182:186]) + ['month', 'dayofyear']\n",
    "\n",
    "# Define target column (189 is label_num)\n",
    "target_column = df.columns[188]\n",
    "\n",
    "# Final feature matrix and target\n",
    "X = df[feature_columns]\n",
    "y = df[target_column]\n",
    "\n",
    "# Final DataFrame\n",
    "final_df = X.copy()\n",
    "final_df['label_num'] = y\n",
    "\n",
    "# Save final DataFrame (optional)\n",
    "final_df.to_csv(\"final_training_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea0e0c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
